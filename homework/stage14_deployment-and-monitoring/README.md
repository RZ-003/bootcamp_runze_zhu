The basic linear regression model I built presents several risks if it were deployed. First of all, the model was trained on a very small and synthetic dataset, so its learned relationship is simplistic and overfitting, so unlikely to generalize. If we apply this model to real-world data, it could be exposed to data quality problems, such as unexpected schema changes, missing values, or new feature ranges. In addition, because the linear regression generalizes indefinitely, predictions outside the training range could be unreasonable and misleading for the decision-making.

To reduce the risks, monitoring must be deployed across the four layers. First of all, at the data layer, I would monitor schema consistency, null checks, and any unusual distributions. Then, at the model layer, I would track error metrics such as rolling MAE or RMSE to catch any drift or degradation. Next, at the system layer, I need to ensure the Flask API returns predictions reliably by tracking the latency and throughput. Last but not least, at the business layer, I will check if the predictions are still helping with the intended goal, like improving accuracy of decisions. If the modelâ€™s predictions is not useful anymore, then I need to consider reconstruct my model.

For the ongoing maintenance, the model owner (data analyst) should handle retraining and updating. The platform team should keep the service running, and the portfolio manager should make sure the outputs are useful. The effective and timely communication is the key when problems occur.